# -*- coding: utf-8 -*-
"""MAJOR_PROJECT_B21AI007_B21AI036_B21CS065.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_T4fQHlbDC0J6pCcDpbMTqZW3mZy-JGX
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import librosa
import soundfile
from glob import glob
import librosa.display
import IPython.display as ipd 
import seaborn as sns 
from collections import Counter 
from sklearn.model_selection import train_test_split  
from scipy.signal import lfilter 
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score 
from sklearn.metrics import precision_score, recall_score, f1_score

import warnings
  
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

import os
Root = "/content/drive/MyDrive/Speech" 
os.chdir(Root)

ls

Emotion = {'01' : 'neutral', '02' : 'calm', '03' : 'happy', '04' : 'sad', '05' : 'angry', '06' : 'fearful', '07' : 'disgust', '08' : 'surprised'}

audio_files = glob("/content/drive/MyDrive/Speech/*/*.wav")

data = pd.DataFrame() 
data['Path'] = [] 
data['Emotion'] = [] 
data

Emotions = []  
path = [] 
gender = []
for i in audio_files:  
  
  path.append(i)  
  p = int(str(i)[58])
  if(p%2==0): 
    gender.append('female') 
    # Emotions.append('female_' + Emotion[str(i)[45:47]]) 
  else: 
    gender.append('male')
    # Emotions.append('male_' + Emotion[str(i)[45:47]])  
  Emotions.append( Emotion[str(i)[45:47]]) 
data['Path'] = path 
data['Emotion'] = Emotions  
data['Gender'] = gender 
# data['gender'] = gender

data



Y = pd.DataFrame(data['Emotion'], columns = ['Emotion']) 
Y

Y_one_hot_encoded = pd.get_dummies(Y , columns = ['Emotion']) 
Y_one_hot_encoded.head()

Encodings_emotion = {}
l = list(Y['Emotion'].unique())
l.sort()  
for i in range(len(l)): 
  Encodings_emotion[l[i]] = i 
print(Encodings_emotion)

for i in range(len(Y)): 
  Y['Emotion'][i] = Encodings_emotion[Y['Emotion'][i]] 
Y

def training_testing_splitting(X , Y , random_state = 7): 
  X_train , X_test , Y_train , Y_test = train_test_split(X  , Y ,test_size  = 0.3 ,  random_state = random_state)  
  return X_train ,X_test , Y_train , Y_test

# model_info = pd.DataFrame() 
# model_info['Feature_extraction_method']  = []
# model_info['Model'] = [] 
# result = pd.DataFrame()  

# result['Training Accuracy' ] = [] 
# result['Testing Accuracy'] = [] 
# result['Precision'] = [] 
# result['Recall'] = [] 
# result['F1-score'] = [] 
# result

"""## EDA"""

k = Counter(data['Emotion']) 
plt.xticks(rotation=45)
plt.bar(k.keys() , k.values())

def plot_(file , emotion):  
  X , sample_rate = librosa.load(file) 
  mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)
  # audio wave
  plt.figure(figsize=(20, 15))
  plt.subplot(3,1,1)
  librosa.display.waveshow(X, sr=sample_rate)
  plt.title('Audio sampled at ' + str(sample_rate) + "Hz for " + str(emotion)) 
  plt.show() 

  # MFCC
  plt.figure(figsize=(16, 10))
  plt.subplot(3,1,1)
  librosa.display.specshow(mfcc, x_axis='time')
  plt.ylabel('MFCC')
  plt.colorbar()   
  plt.title("MFCC for "  + str(emotion))
  plt.show()

labels = list(Encodings_emotion.keys()  ) 
for i in labels: 
  df = data[data['Emotion'] == i  ] 
  plot_(data['Path'][0] , i )

# # CREATE LOG MEL SPECTROGRAM 
# def plot_mel():
# plt.figure(figsize=(10, 5))
# spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) 
# spectrogram = librosa.power_to_db(spectrogram)
# librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');
# plt.title('Mel Spectrogram - Male Fearfull')
# plt.colorbar(format='%+2.0f dB');

"""## FEATURE EXTRACTION"""

X_mfcc = [] 
X_chroma = []
X_mel = [] 

for file in audio_files: 
  signal, sample_rate = librosa.load(file)
  
  # Extract MFCC features
  feature_info = librosa.feature.mfcc(y=signal, sr=sample_rate)
  feature_info = np.mean(feature_info.T, axis=0) 
  X_mfcc.append(np.array(feature_info.tolist())) 
  
  # Extract mel spectrogram features
  feature_info = librosa.feature.melspectrogram(y=signal, sr=sample_rate)
  feature_info = np.mean(feature_info.T, axis=0) 
  X_mel.append(np.array(feature_info.tolist())) 
  
  # Extracting chroma features  
  stft=np.abs(librosa.stft(signal))
  chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)
  X_chroma.append(chroma)

X_mfcc = np.array(X_mfcc) 

X_chroma = np.array(X_chroma) 

X_mel = np.array(X_mel)

pip install keras_tuner

print(X_mfcc.shape , X_chroma.shape , X_mel.shape)

"""## TRAINING THE MODEL FOR MFCC FEATURES"""

X_train , X_test , Y_train , Y_test = training_testing_splitting(X_mfcc , Y_one_hot_encoded )

from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler() 
scaler.fit(X_train) 
X_train = scaler.transform(X_train) 
X_test = scaler.transform(X_test)

y_train = np.array(Y_train)
y_test = np.array(Y_test) 
# y_val = np.array(Y_val)

y_train = np.argmax(y_train , axis = 1) 
y_test = np.argmax(y_test , axis  = 1)   
# y_val = np.argmax(y_val , axis = 1)



"""### ANN"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch  
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils

# model = keras.Sequential()
# model.add(Dense( 32, input_dim= 20 , activation='relu'))
# model.add(Dense(16, activation='relu'))
# model.add(Dense(32, activation='relu')) 
# model.add(Dense( 16, activation='softmax'))
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# model.fit(X_train , Y_train , epochs = 1000 , batch_size = 64 , validation_data = (X_test , Y_test)) 

# print(model.evaluate(x = X_test , y = Y_test))

# print(best_hps.values)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch



# Define the tuner
def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=(20,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8  , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs= 50 ,
             validation_data=(X_test, Y_test),
             callbacks=[early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs=1000,
                    batch_size=32,
                    validation_data=(X_test, Y_test),
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

Y_pred = model.predict(X_test) 
Y_pred = np.argmax(Y_pred , axis = 1)

print(best_hps.values)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

y_test

Y_pred

# y_test: true labels, Y_pred: predicted labels
cm = confusion_matrix(y_test, Y_pred)
cr = classification_report(y_test, Y_pred)
acc = accuracy_score(y_test, Y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

train_loss , train_acc  = model.evaluate(x = X_train , y = Y_train ) 
test_loss , test_acc = model.evaluate( x = X_test , y = Y_test )

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### SVM"""



from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


svm_model = SVC( random_state = 8)

# Define the hyperparameter space to explore
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
}
# Define the grid search object
grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_



y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

y_pred.shape

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the decision tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter space to explore
param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the random forest classifier model
rf_model = RandomForestClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [ 100 , 200 , 500 ],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 15, 20],
    'criterion' :['gini', 'entropy']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()



"""### BAGGING """

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# # Generate some random data
# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=8)

# # Split data into train and test sets
# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=8)

# # Define the base estimator to use
base_estimator = DecisionTreeClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_samples': [0.5, 0.7, 0.9],
    'max_features': [0.5, 0.7, 0.9],
    'base_estimator__max_depth': [5, 10, 15],
}

# Define the bagging classifier to use
bagging_model = BaggingClassifier(base_estimator=base_estimator, random_state=8)

# Define the grid search object
grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Define the KNN model
knn_model = KNeighborsClassifier()

# Define the hyperparameter space to explore
param_grid = {
    'n_neighbors': [2,3, 4,5,6, 7,8, 9 , 10  ],
    'p': [1, 2],
}

# Define the grid search object
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

"""## TRAINING THE MODEL FOR MEL SPECTROGRAM FEATURES"""

X_train , X_test , Y_train , Y_test = training_testing_splitting(X_mel , Y_one_hot_encoded )

from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler() 
scaler.fit(X_train) 
X_train = scaler.transform(X_train) 
X_test = scaler.transform(X_test)

y_train = np.array(Y_train)
y_test = np.array(Y_test) 
# y_val = np.array(Y_val)

y_train = np.argmax(y_train , axis = 1) 
y_test = np.argmax(y_test , axis  = 1)   
# y_val = np.argmax(y_val , axis = 1)



"""### ANN"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch  
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils

# model = keras.Sequential()
# model.add(Dense( 32, input_dim= 20 , activation='relu'))
# model.add(Dense(16, activation='relu'))
# model.add(Dense(32, activation='relu')) 
# model.add(Dense( 16, activation='softmax'))
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# model.fit(X_train , Y_train , epochs = 1000 , batch_size = 64 , validation_data = (X_test , Y_test)) 

# print(model.evaluate(x = X_test , y = Y_test))

# print(best_hps.values)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch



# Define the tuner
def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=( 128 ,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8  , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs= 50 ,
             validation_data=(X_test, Y_test),
             callbacks=[early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs=1000,
                    batch_size=32,
                    validation_data=(X_test, Y_test),
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

"""#### h"""

Y_pred = model.predict(X_test) 
Y_pred = np.argmax(Y_pred , axis = 1)

print(best_hps.values)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

y_test

Y_pred

# y_test: true labels, Y_pred: predicted labels
cm = confusion_matrix(y_test, Y_pred)
cr = classification_report(y_test, Y_pred)
acc = accuracy_score(y_test, Y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

train_loss , train_acc  = model.evaluate(x = X_train , y = Y_train ) 
test_loss , test_acc = model.evaluate( x = X_test , y = Y_test )

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### SVM"""



from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


svm_model = SVC( random_state = 8)

# Define the hyperparameter space to explore
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
}
# Define the grid search object
grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_



y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

y_pred.shape

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the decision tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter space to explore
param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)



"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the random forest classifier model
rf_model = RandomForestClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [ 100 , 200 , 500 ],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 15, 20],
    'criterion' :['gini', 'entropy']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

"""### BAGGING """

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# # Generate some random data
# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=8)

# # Split data into train and test sets
# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=8)

# # Define the base estimator to use
base_estimator = DecisionTreeClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_samples': [0.5, 0.7, 0.9],
    'max_features': [0.5, 0.7, 0.9],
    'base_estimator__max_depth': [5, 10, 15],
}

# Define the bagging classifier to use
bagging_model = BaggingClassifier(base_estimator=base_estimator, random_state=8)

# Define the grid search object
grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Define the KNN model
knn_model = KNeighborsClassifier()

# Define the hyperparameter space to explore
param_grid = {
    'n_neighbors': [2,3, 4,5,6, 7,8, 9 , 10  ],
    'p': [1, 2],
}

# Define the grid search object
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()





"""## TRAINING THE MODEL FOR CHROMA FEATURES"""

X_train , X_test , Y_train , Y_test = training_testing_splitting(X_chroma , Y_one_hot_encoded )

from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler() 
scaler.fit(X_train) 
X_train = scaler.transform(X_train) 
X_test = scaler.transform(X_test)

y_train = np.array(Y_train)
y_test = np.array(Y_test) 
# y_val = np.array(Y_val)

y_train = np.argmax(y_train , axis = 1) 
y_test = np.argmax(y_test , axis  = 1)   
# y_val = np.argmax(y_val , axis = 1)



"""### ANN"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch  
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils

# model = keras.Sequential()
# model.add(Dense( 32, input_dim= 20 , activation='relu'))
# model.add(Dense(16, activation='relu'))
# model.add(Dense(32, activation='relu')) 
# model.add(Dense( 16, activation='softmax'))
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# model.fit(X_train , Y_train , epochs = 1000 , batch_size = 64 , validation_data = (X_test , Y_test)) 

# print(model.evaluate(x = X_test , y = Y_test))

# print(best_hps.values)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch



# Define the tuner
def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=(12 ,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8  , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs= 50 ,
             validation_data=(X_test, Y_test),
             callbacks=[early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs=1000,
                    batch_size=32,
                    validation_data=(X_test, Y_test),
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

"""#### h"""

Y_pred = model.predict(X_test) 
Y_pred = np.argmax(Y_pred , axis = 1)

print(best_hps.values)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

y_test

Y_pred

# y_test: true labels, Y_pred: predicted labels
cm = confusion_matrix(y_test, Y_pred)
cr = classification_report(y_test, Y_pred)
acc = accuracy_score(y_test, Y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

train_loss , train_acc  = model.evaluate(x = X_train , y = Y_train ) 
test_loss , test_acc = model.evaluate( x = X_test , y = Y_test )

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### SVM"""



from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


svm_model = SVC( random_state = 8)

# Define the hyperparameter space to explore
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
}
# Define the grid search object
grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_



y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

y_pred.shape

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the decision tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter space to explore
param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the random forest classifier model
rf_model = RandomForestClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [ 100 , 200 , 500 ],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 15, 20],
    'criterion' :['gini', 'entropy']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### BAGGING """

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# # Generate some random data
# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=8)

# # Split data into train and test sets
# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=8)

# # Define the base estimator to use
base_estimator = DecisionTreeClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_samples': [0.5, 0.7, 0.9],
    'max_features': [0.5, 0.7, 0.9],
    'base_estimator__max_depth': [5, 10, 15],
}

# Define the bagging classifier to use
bagging_model = BaggingClassifier(base_estimator=base_estimator, random_state=8)

# Define the grid search object
grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Define the KNN model
knn_model = KNeighborsClassifier()

# Define the hyperparameter space to explore
param_grid = {
    'n_neighbors': [2,3, 4,5,6, 7,8, 9 , 10  ],
    'p': [1, 2],
}

# Define the grid search object
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



"""## COMBINED FEATURES"""

def extract_feature(file_name):
    X , sample_rate = librosa.load(file_name)
    stft=np.abs(librosa.stft(X))
    result=np.array([])
    
    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
    result=np.hstack((result, mfccs))

    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)
    result=np.hstack((result, chroma))

    mel=np.mean(librosa.feature.melspectrogram(y = X, sr=sample_rate).T,axis=0)
    result=np.hstack((result, mel))
    return result

X_com = []

for file in audio_files: 
  X_com.append(extract_feature(file))

X_com = np.array(X_com)



X_train , X_test , Y_train , Y_test = training_testing_splitting(X_com , Y_one_hot_encoded )

from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler() 
scaler.fit(X_train) 
X_train = scaler.transform(X_train) 
X_test = scaler.transform(X_test)

y_train = np.array(Y_train)
y_test = np.array(Y_test) 
# y_val = np.array(Y_val)

y_train = np.argmax(y_train , axis = 1) 
y_test = np.argmax(y_test , axis  = 1)   
# y_val = np.argmax(y_val , axis = 1)



"""### ANN"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch  
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils

# model = keras.Sequential()
# model.add(Dense( 32, input_dim= 20 , activation='relu'))
# model.add(Dense(16, activation='relu'))
# model.add(Dense(32, activation='relu')) 
# model.add(Dense( 16, activation='softmax'))
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# model.fit(X_train , Y_train , epochs = 1000 , batch_size = 64 , validation_data = (X_test , Y_test)) 

# print(model.evaluate(x = X_test , y = Y_test))

# print(best_hps.values)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch



# Define the tuner
def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=(180,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8  , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs= 50 ,
             validation_data=(X_test, Y_test),
             callbacks=[early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs=1000,
                    batch_size=32,
                    validation_data=(X_test, Y_test),
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

"""#### h"""

Y_pred = model.predict(X_test) 
Y_pred = np.argmax(Y_pred , axis = 1)

print(best_hps.values)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

y_test

Y_pred

# y_test: true labels, Y_pred: predicted labels
cm = confusion_matrix(y_test, Y_pred)
cr = classification_report(y_test, Y_pred)
acc = accuracy_score(y_test, Y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

train_loss , train_acc  = model.evaluate(x = X_train , y = Y_train ) 
test_loss , test_acc = model.evaluate( x = X_test , y = Y_test )

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### SVM"""



from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


svm_model = SVC( random_state = 8)

# Define the hyperparameter space to explore
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
}
# Define the grid search object
grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_



y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

y_pred.shape

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the decision tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter space to explore
param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the random forest classifier model
rf_model = RandomForestClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [ 100 , 200 , 500 ],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 15, 20],
    'criterion' :['gini', 'entropy']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()



"""### BAGGING """

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# # Generate some random data
# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=8)

# # Split data into train and test sets
# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=8)

# # Define the base estimator to use
base_estimator = DecisionTreeClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_samples': [0.5, 0.7, 0.9],
    'max_features': [0.5, 0.7, 0.9],
    'base_estimator__max_depth': [5, 10, 15],
}

# Define the bagging classifier to use
bagging_model = BaggingClassifier(base_estimator=base_estimator, random_state=8)

# Define the grid search object
grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Define the KNN model
knn_model = KNeighborsClassifier()

# Define the hyperparameter space to explore
param_grid = {
    'n_neighbors': [2,3, 4,5,6, 7,8, 9 , 10  ],
    'p': [1, 2],
}

# Define the grid search object
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)

print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

"""# WITH AUDIO AUGMENTATION

### AUDIO AUGMENTATION
"""

# NOISE
def noise(data):
    noise_amp = 0.035*np.random.uniform()*np.amax(data)
    data = data + noise_amp*np.random.normal(size=data.shape[0])
    return data
# # STRETCH
# def stretch(data, rate=0.8):
#     return librosa.effects.time_stretch(data,rate =  rate)
# SHIFT
def shift(data):
    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)
    return np.roll(data, shift_range)
# PITCH
def pitch(data, sampling_rate, pitch_factor=0.7):
    return librosa.effects.pitch_shift(data, sr = sampling_rate,n_steps =  pitch_factor)

def feat_ext(data , sample_rate):
    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)
    return mfcc

def get_feat(path):
    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)
    # normal data
    res1 = feat_ext(data , sample_rate)
    result = np.array(res1)
    #data with noise
    noise_data = noise(data)
    res2 = feat_ext(noise_data , sample_rate)
    result = np.vstack((result, res2))
    #data with stretch and pitch
    new_data = stretch(data)
    data_stretch_pitch = pitch(new_data, sample_rate)
    res3 = feat_ext(data_stretch_pitch , sample_rate)
    result = np.vstack((result, res3))
    return result

X = []  
y = [] 
i = 0 
for file in audio_files: 
  f = get_feat(file) 
  for e in f: 
    X.append(e)   
    y.append(Y['Emotion'][i]) 
  i+=1 
X = np.array(X) 
y = np.array(y)

print(X.shape) 
print(y.shape)

y = pd.DataFrame(y , columns = ['Emotions']) 
y.head()

y = pd.get_dummies(y , columns = ['Emotions']) 
y.head()

y = np.array(y)

X_train , X_test , Y_train , Y_test = training_testing_splitting(X , y )

from sklearn.preprocessing import RobustScaler
scaler = RobustScaler() 
scaler.fit(X_train) 
X_train = scaler.transform(X_train) 
X_test = scaler.transform(X_test)

Y_train = np.array(Y_train ) 
Y_test = np.array(Y_test)

y_train = np.argmax(Y_train , axis = 1) 
y_test = np.argmax(Y_test , axis = 1) 
y_train.shape

pip install keras_tuner

"""### ANN"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch


def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=(20,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8 , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4  , 1e-5 , 1e-6]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4 , 1e-5 , 1e-6]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4 , 1e-5 , 1e-6]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs=50,
             validation_data=(X_test, Y_test) , callbacks = [early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs= 500,
                    batch_size=32,
                    validation_data=(X_test, Y_test) , callbacks = [early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

best_hps.values



Y_pred = model.predict(X_test) 
Y_pred = np.argmax(Y_pred , axis = 1)

print(best_hps.values)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

# y_test: true labels, Y_pred: predicted labels
cm = confusion_matrix(y_test, Y_pred)
cr = classification_report(y_test, Y_pred)
acc = accuracy_score(y_test, Y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()

train_loss , train_acc  = model.evaluate(x = X_train , y = Y_train ) 
test_loss , test_acc = model.evaluate( x = X_test , y = Y_test )

print("Training accuracy is : " , train_acc) 
print("Testing accuracy is : " , test_acc)

from joblib import dump



dump(model, '/content/ann_final.joblib')

"""### SVM"""



from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


svm_model = SVC( random_state = 8)

# Define the hyperparameter space to explore
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
}
# Define the grid search object
grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred) 
# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()





"""### DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the decision tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Define the hyperparameter space to explore
param_grid = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred) 
# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()





"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Define the KNN model
knn_model = KNeighborsClassifier()

# Define the hyperparameter space to explore
param_grid = {
    'n_neighbors': [2,3, 4,5,6, 7,8, 9 , 10  ],
    'p': [1, 2],
}

# Define the grid search object
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)



"""#### MM"""

# y_test: true labels, y_pred: predicted labels
cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)

print("Confusion Matrix:\n", cm)
print("Classification Report:\n", cr)
print("Accuracy: ", acc)

sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Show plot
plt.show()





"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the random forest classifier model
rf_model = RandomForestClassifier(random_state=8)

# Define the hyperparameter space to explore
param_grid = {
    'n_estimators': [ 100 , 200 , 500 ],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 15, 20],
    'criterion' :['gini', 'entropy']
}

# Define the grid search object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_


y_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, y_pred)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)


print("Testing accuracy:", test_acc)
print("Training accuracy: ", train_acc)
print("Best hyperparameters: ", best_params)

"""### ANN with PCA"""

from sklearn.decomposition import PCA

pca = PCA(n_components = 0.99) 
pca.fit(X_train) 
X_train = pca.transform(X_train) 
X_test = pca.transform(X_test) 
X_train.shape

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner.tuners import RandomSearch


def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=16),
                           input_shape=(17,),
                           activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))
    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.05)))

    # Add hidden layers
    num_layers = hp.Int('num_layers', min_value=1, max_value=10)
    for i in range(num_layers):
        model.add(layers.Dense(units=hp.Int(f'units{i+2}', min_value=16 , max_value=512, step=8),
                               activation=hp.Choice(f'activation{i+2}', values=['relu', 'tanh', 'sigmoid'])))
        model.add(layers.Dropout(rate=hp.Float(f'dropout{i+2}', min_value=0.0, max_value=0.5, step=0.1)))
    model.add(layers.Dense(units= 8 , activation='softmax'))
    
    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])
    if optimizer == 'adam':
        optimizer = keras.optimizers.Adam(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4  , 1e-5 , 1e-6]))
    elif optimizer == 'rmsprop':
        optimizer = keras.optimizers.RMSprop(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4 , 1e-5 , 1e-6]))
    elif optimizer == 'sgd':
        optimizer = keras.optimizers.SGD(
            learning_rate=hp.Choice('learning_rate', values=[0.1, 1e-2, 1e-3, 1e-4 , 1e-5 , 1e-6]))
    model.compile(
        optimizer=optimizer,
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model

early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 50)

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='my_project')

# Search for the best hyperparameters
tuner.search(x=X_train, y=Y_train,
             epochs=50,
             validation_data=(X_test, Y_test) , callbacks = [early_stopping])

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps)

# Build the model with the best hyperparameters
model = build_model(best_hps)

# Train the model on the full dataset
history = model.fit(x=X_train, y=Y_train,
                    epochs= 500,
                    batch_size=32,
                    validation_data=(X_test, Y_test) , callbacks = [early_stopping])

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(x=X_test, y=Y_test)
print('Test accuracy:', test_acc)

import matplotlib.pyplot as plt

# Train and test losses
train_losses = history.history['loss']
test_losses = history.history['val_loss']

# Train and test accuracy
train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

# Number of epochs
epochs = range(1, len(train_losses) + 1)

# Plot losses
plt.plot(epochs, train_losses, label='Training losses')
plt.plot(epochs, test_losses , label='Testing losses')
plt.title('Training and Testing losses')
plt.xlabel('Epochs')
plt.ylabel('losses')
plt.legend()

# Show plot
plt.show()

# Plot accuracy
plt.plot(epochs, train_acc , label='Training accuracy')
plt.plot(epochs, test_acc,  label='Testing accuracy')
plt.title('Training and Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show plot
plt.show()

